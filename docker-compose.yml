
---
x-airflow-common:
  &airflow-common
  # In order to add custom dependencies or upgrade provider packages you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the "build" line below, Then run `docker-compose build` to build the images.
  # image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.8.1}
  build:
      context: ./containers/airflow
      dockerfile: Dockerfile 
  environment:
    &airflow-common-env
    BOOTSTRAP_SERVER: ${BOOTSTRAP_SERVER}
    DBT_CWD: ${DBT_CWD}
    GITHUB_PAT: ${GITHUB_PAT}
    POSTGRES_DB: ${POSTGRES_DB}
    POSTGRES_USER: ${POSTGRES_USER}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    POSTGRES_PORT: ${PORT}
    POSTGRES_HOST: ${POSTGRES_HOST}
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
    AIRFLOW__WEBSERVER__CATCHUP_BY_DEFAULT: 'false'
    AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
    # AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT: '{"conn_type": "google_cloud_platform", "extra": {"key_path": "${GOOGLE_APPLICATION_CREDENTIALS}","scope": "https://www.googleapis.com/auth/cloud-platform", "project": "airflow", "num_retries": 1}}'
    # yamllint disable rule:line-length
    # Use simple http server on scheduler for health checks
    # See https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html#scheduler-health-check-server
    # yamllint enable rule:line-length
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    # WARNING: Use _PIP_ADDITIONAL_REQUIREMENTS option ONLY for a quick checks
    # for other purpose (development, test and especially production usage) build/extend Airflow image.
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
  env_file:
      - .env
  volumes:
    - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-.}/utils:/opt/airflow/utils
    - ${AIRFLOW_PROJ_DIR:-.}/kafka_consumer:/opt/airflow/kafka_consumer
    - ${AIRFLOW_PROJ_DIR:-.}/kafka_producer:/opt/airflow/kafka_producer
    - ${AIRFLOW_PROJ_DIR:-.}/gh_app/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-.}/gh_app/config:/opt/airflow/config
    - ${AIRFLOW_PROJ_DIR:-.}/gh_app/plugins:/opt/airflow/plugins
    - ${DBT_PROFILE_DIR:-./dbt/gh_app/profiles.yml}:/home/airflow/.dbt/profiles.yml
    - ${DBT_FOLDER_PATH:-./dbt/gh_app}:/opt/airflow/dags/dbt/gh_app
  depends_on:
    &airflow-common-depends-on
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy
  networks:
    iceberg_net:
services:    
  postgres:
    image: postgres:13
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always
    networks:
      iceberg_net:

  redis:
    image: redis:latest
    container_name: airflow-redis
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always
    networks:
      iceberg_net:

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    container_name: airflow-webserver
    ports:
      - "8080:8080"
      - "8001:8001"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    container_name: airflow-scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    container_name: airflow-worker
    healthcheck:
      # yamllint disable rule:line-length
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      <<: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: "0"
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-triggerer:
    <<: *airflow-common
    command: triggerer
    container_name: airflow-triggerer
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        if [[ -z "${AIRFLOW_UID}" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m"
          echo "If you are on Linux, you SHOULD follow the instructions below to set "
          echo "AIRFLOW_UID environment variable, otherwise files will be owned by root."
          echo "For other operating systems you can get rid of the warning with manually created .env file:"
          echo "    See: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user"
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources="false"
        if (( mem_available < 4000 )) ; then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m"
          echo "At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))"
          echo
          warning_resources="true"
        fi
        if (( cpus_available < 2 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m"
          echo "At least 2 CPUs recommended. You have $${cpus_available}"
          echo
          warning_resources="true"
        fi
        if (( disk_available < one_meg * 10 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m"
          echo "At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))"
          echo
          warning_resources="true"
        fi
        if [[ $${warning_resources} == "true" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m"
          echo "Please follow the instructions to increase amount of resources available:"
          echo "   https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#before-you-begin"
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ''
    user: "0:0"
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}:/sources

  airflow-cli:
    <<: *airflow-common
    profiles:
      - debug
    environment:
      <<: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: "0"
    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252
    command:
      - bash
      - -c
      - airflow

  # You can enable flower by adding "--profile flower" option e.g. docker-compose --profile flower up
  # or by explicitly targeted on the command line e.g. docker-compose up flower.
  # See: https://docs.docker.com/compose/profiles/
  flower:
    <<: *airflow-common
    command: celery flower
    profiles:
      - flower
    ports:
      - "5555:5555"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully 

  minio:
    image: 'minio/minio:latest'
    hostname: minio
    container_name: minio
    ports:
      - '9000:9000'  
      - '9001:9001'
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
      MINIO_DOMAIN: minio
    networks:
      iceberg_net:
        aliases:
          - lakehouse.minio
    command: server --console-address ":9001" /data
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    volumes:
      - minio-db:/data
    restart: always

  upstream:
    image: postgres:15
    container_name: upstreamdb
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: gh_raw_db
    ports:
      - "5433:5432"
    volumes:
      - upstream-db-volume:/var/lib/postgresql/data
      - ./gh_app/ddl/gh_ddl.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      iceberg_net:

  createbuckets:
    image: minio/mc:latest
    container_name: createbuckets
    depends_on:
      - minio
    volumes:
      - ./containers/minio/create-bucket.sh:/usr/local/bin/create-bucket.sh
      - minio-db:/data
    entrypoint: ['/bin/sh', '-c', '/usr/local/bin/create-bucket.sh']
    networks:
      iceberg_net:
  
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    networks:
      iceberg_net:


  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    expose:
      - '29092'
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER_NET
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      iceberg_net:
  
  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:latest
  #   depends_on:
  #     - kafka
  #   ports:
  #     - "9021:9021"
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: kafka:29092
  #     CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONTROL_CENTER_COMMAND_TOPIC_PARTITIONS: 1
  #     CONTROL_CENTER_METRICS_TOPIC_PARTITIONS: 1
  #     CONTROL_CENTER_STREAMS_APPLICATION_ID: control-center
  #     CONTROL_CENTER_SYSTEM_TOPIC_PARTITIONS: 1
  #     CONTROL_CENTER_CONNECT_CLUSTER_PARTITIONS: 1
  
  init-kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c', '/usr/local/bin/init-kafka-topics.sh' ]
    volumes:
      - ./containers/kafka/init-kafka-topics.sh:/usr/local/bin/init-kafka-topics.sh
    networks:
      iceberg_net:
  
  spark-master:
    image: spark-image
    container_name: spark-master
    entrypoint: ['./entrypoint.sh', 'master']
    build:
      context: ./containers/spark
      dockerfile: Dockerfile
      # target: spark-iceberg
    depends_on:
      - rest
      - minio
    volumes:
      - ./kafka_consumer:/opt/spark/kafka_consumer:rw
      - ./utils:/opt/spark/utils/:rw
      - ./warehouse:/home/iceberg/warehouse:rw
      - spark-logs:/opt/spark/spark-events:rw
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
      - BOOTSTRAP_SERVER=${BOOTSTRAP_SERVER}
      - SPARK_EXECUTOR_MEMORY=4G
      - SPARK_DRIVER_MEMORY=2G
      - SPARK_EXECUTOR_CORES=2
      - SPARK_DRIVER_CORES=1
    ports:
      - 4040:4040
      - 9090:8080
      - 7077:7077
    env_file:
      - .env.spark
    networks:
      iceberg_net:
  
  spark-worker:
    container_name: spark-worker
    image: spark-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      - spark-master
      - rest
    volumes:
      - ./kafka_consumer:/opt/spark/kafka_consumer:rw
      - ./utils:/opt/spark/utils/:rw
      - spark-logs:/opt/spark/spark-events:rw
    env_file:
      - .env.spark
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
      - BOOTSTRAP_SERVER=${BOOTSTRAP_SERVER}
      - SPARK_EXECUTOR_MEMORY=4G
      - SPARK_DRIVER_MEMORY=2G
      - SPARK_EXECUTOR_CORES=2
      - SPARK_DRIVER_CORES=1
    networks:
      iceberg_net:

  spark-history-server:
    container_name: spark-history
    image: spark-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      - spark-master
      - rest
    env_file:
      - .env.spark
    volumes:
      - spark-logs:/opt/spark/spark-events:rw
    ports:
      - 18080:18080
    networks:
      iceberg_net:
  
  rest:
    image: tabulario/iceberg-rest
    container_name: iceberg-rest
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://lakehouse/bronze/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000
      - CATALOG_S3_PATH__STYLE__ACCESS=true
    # volumes:
    #   - sqlite-db:/tmp
    networks:
      iceberg_net:
  
  mariadb:
    image: 'mariadb:10.11.2'
    hostname: mariadb
    container_name: mariadb
    ports:
      - '3306:3306'
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_USER: admin
      MYSQL_PASSWORD: admin
      MYSQL_DATABASE: metastore_db
    networks:
      iceberg_net:

  hive-metastore:
    image: 'bitsondatadev/hive-metastore:latest'
    hostname: hive-metastore
    container_name: hive-metastore
    ports:
      - '9083:9083' # Metastore Thrift
    volumes:
      - ./containers/hive/metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    environment:
      METASTORE_DB_HOSTNAME: mariadb
    depends_on:
      - mariadb
    networks:
      iceberg_net:

  trino:
    image: trinodb/trino:latest
    hostname: trino_container 
    container_name: trino
    ports:
      - 1080:8080 
    volumes:
      - ./containers/trino/etc:/etc/trino/
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
    networks:
      iceberg_net:
    restart: always
    depends_on: 
      - minio 
      - hive-metastore 
      - rest
  
  # trino-setup:
  #   build: ./containers/trino/
  #   container_name: trino-cli
  #   restart: "no"
  #   networks:
  #     iceberg_net:
  #   depends_on:
  #     - trino



volumes:
  postgres-db-volume:
  upstream-db-volume:
  kafka-data:
  zookeeper-data:
  zookeeper-log:
  spark-logs:
  minio-db:
  # sqlite-db:

networks:
  iceberg_net:

